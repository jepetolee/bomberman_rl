# Frozen ViT ν•™μµ κ°€μ΄λ“

ViT λ°±λ³Έμ„ κ³ μ •ν•κ³ , Value Networkμ™€ TRMλ§ κ°•ν™”ν•™μµμ„ μν–‰ν•λ” λ°©λ²•μ…λ‹λ‹¤.

## π― λ©μ 

μ‚¬μ „ ν•™μµλ ViT λ°±λ³Έμ νΉμ§• μ¶”μ¶ λ¥λ ¥μ„ μ μ§€ν•λ©΄μ„, Value Networkμ™€ TRMλ§ RLλ΅ λ―Έμ„Έ μ΅°μ •ν•©λ‹λ‹¤.

## π“‹ μ„¤μ • λ°©λ²•

### 1. ν™κ²½ λ³€μ μ„¤μ •

```bash
# Frozen ViT λ¨λ“ ν™μ„±ν™”
export BOMBER_FROZEN_VIT=1

# μ‚¬μ „ ν•™μµ λ¨λΈ κ²½λ΅ μ§€μ •
export PPO_MODEL_PATH=data/policy_models/policy_phase2.pt

# TRM recurrent λ¨λ“ ν™μ„±ν™” (μ„ νƒ)
export BOMBER_USE_TRM=1
```

### 2. μ‹¤ν–‰

```bash
# A3C μ»¤λ¦¬νλΌ λ¬λ‹ (Frozen ViT λ¨λ“)
BOMBER_FROZEN_VIT=1 \
PPO_MODEL_PATH=data/policy_models/policy_phase2.pt \
python3 a3c_gpu_train.py \
  --num-workers 4 \
  --total-rounds 50000 \
  --model-path data/policy_models/policy_phase2.pt
```

## π”§ λ™μ‘ μ›λ¦¬

### ν•™μµλλ” νλΌλ―Έν„°

1. **Value Network** (`model.v_head`)
   - κ°€μΉ μμΈ΅μ„ μ„ν• λ„¤νΈμ›ν¬
   - RL ν™κ²½μ—μ„ λ³΄μƒ μ‹ νΈλ¥Ό ν†µν•΄ ν•™μµ

2. **TRM (Tiny Recursive Model)**
   - `trm_patch_proj`: TRMμ© ν¨μΉ μ„λ² λ”©
   - `trm_pos_embed`: μ„μΉ μ„λ² λ”©
   - `trm_net`: μ¬κ·€ μ¶”λ΅  λ„¤νΈμ›ν¬

3. **Policy Head** (`model.pi_head`)
   - TRMκ³Ό μ—°κ²°λ μ •μ±… μ¶λ ¥ λ μ΄μ–΄

### κ³ μ •λλ” νλΌλ―Έν„°

1. **ViT λ°±λ³Έ** (`model.vit`)
   - λ¨λ“  ViT λ μ΄μ–΄ (ν¨μΉ μ„λ² λ”©, νΈλμ¤ν¬λ¨Έ λΈ”λ΅, μ •κ·ν™”)
   - μ‚¬μ „ ν•™μµλ νΉμ§• μ¶”μ¶ λ¥λ ¥ μ μ§€

## π“ λ³΄μƒ μ •μ±… ν™•μΈ κ²°κ³Ό

### COIN_FOUND μ΄λ²¤νΈ

- **λ°μƒ μ΅°κ±΄**: ν¬λ μ΄νΈλ¥Ό νκ΄΄ν•μ—¬ μ½”μΈμ΄ λ“λ¬λ‚  λ•
- **λ³΄μƒ**: 0.1 (λ‚®μ€ λ³΄μƒ)
- **μ„μΉ**: `environment.py`μ `update_bombs()` ν•¨μ

### BFS λ§µκ³Ό λ³΄μƒ

**ν„μ¬ μƒνƒ:**
- BFS λ§µμ΄ νΉμ§• λ§µμ— ν¬ν•¨λμ§€ μ•μ
- κ±°λ¦¬ κΈ°λ° shaping reward μ—†μ
- μ μ μ½”μΈκ³Ό μ•„κµ°μ μ½”μΈμ„ κµ¬λ¶„ν•μ§€ μ•μ

**νΉμ§• λ§µ κµ¬μ΅°:**
```
grid[0]: λ²½
grid[1]: ν¬λ μ΄νΈ
grid[2]: λΉ κ³µκ°„
grid[3]: μ½”μΈ (λ¨λ“  μ½”μΈ, κµ¬λ¶„ μ—†μ)
grid[4]: ν­νƒ„
grid[5]: ν­λ°
grid[6]: μμ‹ 
grid[7]: μ•„κµ°
grid[8]: μ 
grid[9]: μ„ν— λ§µ
```

**κ°μ„  μ μ•:**
1. μ μ μ½”μΈκΉμ§€μ BFS κ±°λ¦¬λ¥Ό νΉμ§• λ§µμ— μ¶”κ°€ (grid[10])
2. κ±°λ¦¬ κΈ°λ° shaping reward μ¶”κ°€
3. μ μ μ½”μΈμ— λ” λ†’μ€ λ³΄μƒ λ¶€μ—¬

## π€ μ‹¤ν–‰ μμ 

### μ „μ²΄ νμ΄ν”„λΌμΈ

```bash
# 1. μ‚¬μ „ ν•™μµ λ¨λΈ ν™•μΈ
ls -lh data/policy_models/policy_phase2.pt

# 2. Frozen ViT λ¨λ“λ΅ μ»¤λ¦¬νλΌ λ¬λ‹
BOMBER_FROZEN_VIT=1 \
PPO_MODEL_PATH=data/policy_models/policy_phase2.pt \
python3 a3c_gpu_train.py \
  --num-workers 4 \
  --total-rounds 50000 \
  --results-dir results/frozen_vit

# 3. λ³΄μƒ μ •μ±… ν™•μΈ
python3 check_coin_reward.py --check-events --check-reward

# 4. λ¨λΈ ν‰κ°€
python3 evaluate_model.py \
  --model-path results/frozen_vit/ppo_model.pt \
  --rounds 50
```

## π“ μμƒ ν¨κ³Ό

1. **ν•™μµ μ•μ •μ„±**: ViT λ°±λ³Έ κ³ μ •μΌλ΅ νΉμ§• κ³µκ°„ μ•μ •ν™”
2. **ν•™μµ μ†λ„**: ν•™μµ νλΌλ―Έν„° κ°μ†λ΅ λΉ λ¥Έ μλ ΄
3. **μ „μ΄ ν•™μµ**: μ‚¬μ „ ν•™μµλ νΉμ§• ν™μ©

## β οΈ μ£Όμμ‚¬ν•­

1. **λ¨λΈ νΈν™μ„±**: `PolicyValueViT_TRM_Hybrid` λ¨λΈλ§ μ§€μ›
2. **μ‚¬μ „ ν•™μµ ν•„μ**: ViT λ°±λ³Έμ΄ μ‚¬μ „ ν•™μµλμ–΄ μμ–΄μ•Ό ν•¨
3. **TRM ν™μ„±ν™”**: RL λ‹¨κ³„μ—μ„λ” `use_trm=True`λ΅ μ„¤μ •

## π” λ””λ²„κΉ…

### Frozen ViT λ¨λ“ ν™•μΈ

```python
# ν•™μµ μ¤‘ λ΅κ·Έ ν™•μΈ
[Frozen ViT] ViT λ°±λ³Έ κ³ μ •, Value Networkμ™€ TRMλ§ ν•™μµ
[Frozen ViT Optimizer] Trainable parameters: X,XXX
[Frozen ViT Optimizer] Total parameters: XX,XXX
[Frozen ViT Optimizer] Frozen (ViT): XX,XXX
```

### νλΌλ―Έν„° ν™•μΈ

```python
import torch
from agent_code.ppo_agent.models.vit_trm import PolicyValueViT_TRM_Hybrid

model = PolicyValueViT_TRM_Hybrid(...)

# ViT νλΌλ―Έν„° ν™•μΈ (κ³ μ •λμ–΄μ•Ό ν•¨)
for param in model.vit.parameters():
    print(f"ViT param requires_grad: {param.requires_grad}")  # False

# TRM νλΌλ―Έν„° ν™•μΈ (ν•™μµλμ–΄μ•Ό ν•¨)
for param in model.trm_net.parameters():
    print(f"TRM param requires_grad: {param.requires_grad}")  # True
```

## π“ μ”μ•½

- **Frozen ViT λ¨λ“**: `BOMBER_FROZEN_VIT=1` ν™κ²½ λ³€μλ΅ ν™μ„±ν™”
- **ν•™μµ νλΌλ―Έν„°**: Value Network + TRM + Policy Head
- **κ³ μ • νλΌλ―Έν„°**: ViT λ°±λ³Έ μ „μ²΄
- **λ³΄μƒ μ •μ±…**: COIN_FOUNDλ” 0.1, BFS λ§µμ€ ν„μ¬ λ―Έμ‚¬μ©

